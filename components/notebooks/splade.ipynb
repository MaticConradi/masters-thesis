{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from os import path\n",
    "import re\n",
    "from json import load, dump\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from utils.storage import list_processed_mmd_files, list_sparse_vector_files, download_plain_text, upload_sparse_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f06449",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"naver/splade-cocondenser-ensembledistil\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "model.eval()\n",
    "\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "\tchunk_size=700,\n",
    "\tchunk_overlap=100,\n",
    "\tlength_function=len,\n",
    "\tis_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af76deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_processed_mmd_files()\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor() as executor:\n",
    "\tplain = list(tqdm(executor.map(download_plain_text, files), total=len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorFiles = list_sparse_vector_files()\n",
    "print(f\"Found {len(vectorFiles)} vector files\")\n",
    "\n",
    "for filename, text in tqdm(zip(files, plain), total=len(files)):\n",
    "\tif filename in vectorFiles:\n",
    "\t\tcontinue\n",
    "\n",
    "\tchunks = splitter.split_text(text)\n",
    "\tindex = 0\n",
    "\n",
    "\toutput = {}\n",
    "\n",
    "\tfor i in range(0, len(chunks), BATCH_SIZE):\n",
    "\t\tbatch = chunks[i:i + BATCH_SIZE]\n",
    "\n",
    "\t\ttokens = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "\t\ttokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = model(**tokens)\n",
    "\n",
    "\t\tvectors = torch.max(\n",
    "\t\t\ttorch.log(1 + torch.relu(outputs.logits)) * tokens['attention_mask'].unsqueeze(-1),\n",
    "\t\t\tdim=1\n",
    "\t\t)[0].squeeze()\n",
    "\n",
    "\t\tfor j in range(len(batch)):\n",
    "\t\t\tindices = vectors[j].nonzero().squeeze().cpu().tolist()\n",
    "\t\t\tif not isinstance(indices, list):\n",
    "\t\t\t\tindices = [indices]\n",
    "\n",
    "\t\t\tif len(indices) == 0:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tweights = vectors[j][indices].cpu().tolist()\n",
    "\t\t\toutput[index] = dict(zip(indices, weights))\n",
    "\n",
    "\t\t\tindex += 1\n",
    "\n",
    "\tupload_sparse_vectors(filename, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
